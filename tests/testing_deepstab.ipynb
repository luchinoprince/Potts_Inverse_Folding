{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook we will show how to leverage DeepStabT to get melting temperature prediction for the sythetic proteins generated from the different models under consideration in the manuscript. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "# https://github.com/CSBiology/deepStabP/blob/main/src/Api/requirements.txt\n",
    "import sentencepiece\n",
    "import torch\n",
    "import pandas as pd\n",
    "import gc\n",
    "import sys   \n",
    "sys.path.insert(1, \"./../../deepStabP/src/Api/app/\")\n",
    "from fastapi import APIRouter\n",
    "from pydantic import BaseModel\n",
    "from transformers import  T5EncoderModel, T5Tokenizer\n",
    "from tqdm.auto import *              # https://github.com/CSBiology/deepStabP/blob/main/src/Api/app/predictor.py\n",
    "from predictor import *              # https://github.com/CSBiology/deepStabP/blob/main/src/Api/app/predictor.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/home/lucasilva/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.7.7 to v2.1.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../trained_model/b25_sampled_10k_tuned_2_d01/checkpoints/epoch=1-step=2316.ckpt`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deepSTAPpMLP(\n",
       "  (zero_layer): Linear(in_features=1064, out_features=4098, bias=True)\n",
       "  (zero_dropout): Dropout1d(p=0.1, inplace=False)\n",
       "  (first_layer): Linear(in_features=4098, out_features=512, bias=True)\n",
       "  (first_dropout): Dropout1d(p=0.1, inplace=False)\n",
       "  (second_layer): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (second_dropout): Dropout1d(p=0.1, inplace=False)\n",
       "  (third_layer): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (third_dropout): Dropout1d(p=0.1, inplace=False)\n",
       "  (seventh_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (species_layer_one): Linear(in_features=1, out_features=20, bias=True)\n",
       "  (species_layer_two): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (species_dropout): Dropout1d(p=0.1, inplace=False)\n",
       "  (batch_norm0): LayerNorm((4098,), eps=1e-05, elementwise_affine=True)\n",
       "  (batch_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (batch_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (batch_norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (lysate): Linear(in_features=1, out_features=20, bias=True)\n",
       "  (lysate2): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (lysate_dropout): Dropout1d(p=0.1, inplace=False)\n",
       "  (cell): Linear(in_features=1, out_features=20, bias=True)\n",
       "  (cell2): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (cell_dropout): Dropout1d(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mirrored in dotnet Shared/DeepStabP.Types.fs\n",
    "class FastaRecord(BaseModel):\n",
    "    header      : str\n",
    "    sequence    : str\n",
    "\n",
    "# mirrored in dotnet Shared/DeepStabP.Types.fs\n",
    "class PredictorInfo(BaseModel):\n",
    "    growth_temp : int\n",
    "    mt_mode     : str # \"Lysate\" or \"Cell\"\n",
    "    fasta       : list[FastaRecord]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "alphabet='ACDEFGHIKLMNPQRSTVWY-'\n",
    "default_index = alphabet.index('-')\n",
    "aa_index = defaultdict(lambda: default_index, {alphabet[i]: i for i in range(len(alphabet))})\n",
    "aa_index_inv = dict(map(reversed, aa_index.items()))\n",
    "\n",
    "def get_str(seq_num, aa_index_inv):\n",
    "    seq_str = \"\"\n",
    "    #seq_num = msa_train[0,::]\n",
    "    for num in seq_num:\n",
    "        #print(num)\n",
    "        seq_str += aa_index_inv[num.item()]\n",
    "    return seq_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am at protein 132, sample 9 at distance 0.85\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "device = 0\n",
    "model.to(device)\n",
    "prediction_net.to(device)\n",
    "import os\n",
    "import pickle\n",
    "folder_esm = \"/home/lucasilva/new_synthetic_proteins/\"\n",
    "with open(os.path.join(folder_esm, \"samples_ardca_superfamily_new\"), mode=\"rb\") as f: \n",
    "    res_esm_full=pickle.load(f)\n",
    "idx = 0\n",
    "first = True\n",
    "gts = [0,12,25,37]\n",
    "for  gt in gts:\n",
    "    for id in res_esm_full.keys():\n",
    "        idx += 1\n",
    "        for key in res_esm_full[id].keys():\n",
    "            num_seqs = res_esm_full[id][key]\n",
    "            nseq = num_seqs.shape[0]\n",
    "            for n in range(nseq):\n",
    "                print(f\"I am at protein {idx}, sample {n} at distance {key}\", end='\\r')\n",
    "                str_seq = get_str(num_seqs[n,:], aa_index_inv)\n",
    "                str_seq2 = \" \".join(str_seq)\n",
    "                fasta_record_1 = FastaRecord(header=id, sequence=str_seq2)\n",
    "                predictor_info = PredictorInfo(\n",
    "                                growth_temp=gt,\n",
    "                                mt_mode=\"Lysate\",\n",
    "                                fasta=[fasta_record_1])\n",
    "                prediction = determine_tm(predictor_info.fasta, predictor_info.mt_mode, predictor_info.growth_temp, model, prediction_net, new_features, tokenizer, device=device)\n",
    "                prediction['Dist'] = float(key)\n",
    "                prediction['Seq'] = str_seq\n",
    "                prediction['Growth_Temp'] = gt\n",
    "                if first==True:\n",
    "                    result_esm = prediction\n",
    "                    first = False\n",
    "                else:\n",
    "                    result_esm = pd.concat([result_esm, prediction], axis=0)\n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
